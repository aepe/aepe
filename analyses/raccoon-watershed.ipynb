{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "gis",
   "display_name": "gis"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "import os\n",
    "#sys.path.append(\"C:\\\\Users\\\\mnowatz\\\\Documents\\\\Dev\\\\aepe\")\n",
    "#print(sys.path)\n",
    "import psycopg2\n",
    "import requests\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import database as db\n",
    "import re\n",
    "from xml.etree.ElementTree import ElementTree, Element, SubElement\n",
    "import io\n",
    "import json\n",
    "import openpyxl\n",
    "import csv\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "from openpyxl.styles.alignment import Alignment\n",
    "import apsim.apsim.wrapper as apsim\n",
    "from apsim.apsim.daymet import Weather\n",
    "from apsim.apsim_input_writer import get_date, add_management_year\n",
    "from apsim import run_apsim\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbconn = db.connect_to_db('database.ini')\n",
    "raccoon_2018 = 'raccoon.raccoon_clu_ssurgo_2018'\n",
    "#raccoon = pd.read_sql(f\"SELECT * FROM {raccoon_2018} LIMIT 200;\", dbconn)\n",
    "#greene = pd.read_sql(f\"SELECT * FROM {raccoon_2018} WHERE County='Greene';\", dbconn)\n",
    "#greene_soils = pd.read_sql(f\"SELECT DISTINCT mukey FROM {raccoon_2018} where County='Greene';\", dbconn)\n",
    "#field_25 = pd.read_sql(f\"SELECT * FROM {raccoon_2018} WHERE clukey=2515723;\", dbconn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "spin_up_corn = json.loads( open( 'crop_jsons/maize.json', 'r' ).read() )\n",
    "spin_up_soybean = json.loads( open( 'crop_jsons/soybean.json', 'r' ).read() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Get the counties we are interested in."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Returns a list of all unique entries in a column.\n",
    "\n",
    "Args:\n",
    "    dbconn {database connection} -- connection to postgresql database\n",
    "    table {str} -- table name\n",
    "    id_column (str) -- column of interest.\n",
    "Returns:\n",
    "    list of all unique entries in a table column\n",
    "'''\n",
    "def get_distinct(dbconn, table, id_column):\n",
    "    entries = pd.read_sql(f'SELECT DISTINCT {id_column} FROM {table};', dbconn)\n",
    "    entries = entries[id_column].tolist()\n",
    "    return entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bv_query = 'SELECT * FROM raccoon.raccoon_clu_ssurgo_2018 WHERE fips = \\'IA021\\';'\n",
    "'''Get info for a county of interest from a geopandas df\n",
    "Args:\n",
    "    dbconn {database connection} -- connection to postgresql database\n",
    "    table {str} -- name of geopd table\n",
    "    fips {str} -- fips id of the desired county eg. 'IA021'\n",
    "    geom {str} -- column name that contains shape geometry\n",
    "Returns:\n",
    "    geopandas dataframe with county info\n",
    "'''\n",
    "def get_county(dbconn, table, fips, geom, limit=False, limit_num=100):\n",
    "    #Get watershed as geopandas df\n",
    "    if limit:\n",
    "        query = f'SELECT * FROM {table} WHERE fips = \\'{fips}\\' LIMIT {limit_num};'\n",
    "    else:\n",
    "        query = f'SELECT * FROM {table} WHERE fips = \\'{fips}\\';'\n",
    "    county_gpd = gpd.read_postgis(query, dbconn, geom_col=geom)\n",
    "    return county_gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#buena_vista = get_county(dbconn, 'raccoon.raccoon_clu_ssurgo_2018', 'IA021', \"wkb_geometry\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Get the county centroid for creating APSIM met files"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Find and return the centroid of a geopandas geometry\n",
    "\n",
    "Args: \n",
    "    geodf {dataframe} -- geopandas dataframe\n",
    "    id {string} -- the id of interest in the geodf (e.g., 'fips' for county column)\n",
    "    geometry (string) - geopd column with geometries\n",
    "\n",
    "Returns:\n",
    "    {np.array} -- lat and longitude of geometry\n",
    "'''\n",
    "def get_centroid(geodf, id, geometry):\n",
    "    #get the geometry of interest by id - 'fips' for a county\n",
    "    geom = geodf[[id, geometry]]\n",
    "    #dissolve geometries to make one big geometry\n",
    "    dissolved_geom = geom.dissolve(by=id)\n",
    "    #find the centroid of the dissolved geometry and return its long, lat\n",
    "    centroid = dissolved_geom[geometry].centroid\n",
    "    coords = np.vstack([centroid.x, centroid.y]).T\n",
    "    #change to array and lat, long\n",
    "    centroid_coords = np.array([coords[0][1], coords[0][0]])\n",
    "    return centroid_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bv_centroid = get_centroid(buena_vista, 'fips', \"wkb_geometry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Get the weather for given centroid and write to a .met file\n",
    "\n",
    "Args:\n",
    "    lat {float} -- latitude of centroid\n",
    "    long {float} -- longitude of centroid\n",
    "    year_star {int} -- starting year of weather data\n",
    "    year_end {int} -- ending year of weather data\n",
    "    path {str} -- path to write the met files\n",
    "    filename {str} -- name to give the .met file\n",
    "\n",
    "Returns:\n",
    "    None\n",
    "'''\n",
    "def create_met(lat, long, start_year, end_year, filename, path='apsim_files/met_files'):\n",
    "    weather_obj = Weather().from_daymet(lat, long, start_year, end_year)\n",
    "    weather_obj.write_met_file(f'{path}/{filename}.met')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# greene = get_county(dbconn, 'raccoon.raccoon_clu_ssurgo_2018', 'IA073', \"wkb_geometry\")\n",
    "# greene_centroid = get_centroid(greene, 'fips', \"wkb_geometry\")\n",
    "# create_met(greene_centroid[0], greene_centroid[1], 2012, 2019, 'greene')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_excel_met(lat, long, start_year, end_year, county_name):\n",
    "    wth_obj = Weather().from_daymet(lat, long, 1980, 2019)\n",
    "    wth_df = wth_obj.data\n",
    "    tav = round(wth_df[ 'maxt' ].mean(), 1)\n",
    "    amp = round(wth_df['maxt'].max(), 1)\n",
    "    #greene_df.to_excel('greene.xlsx', index=False)\n",
    "    wb = openpyxl.Workbook()\n",
    "    ws = wb.active\n",
    "    ws.alignment = Alignment(horizontal=\"left\")\n",
    "    for r in dataframe_to_rows(wth_df, index=False, header=True):\n",
    "        ws.append(r)\n",
    "    for cells in ws.iter_rows():\n",
    "        for cell in cells:\n",
    "            cell.alignment = Alignment(horizontal=\"left\")\n",
    "    ws.insert_rows(2)\n",
    "    ws['A2'] = '()'\n",
    "    ws['B2'] = '()'\n",
    "    ws['C2'] = '(MJ/m2)'\n",
    "    ws['D2'] = '(oC)'\n",
    "    ws['E2'] = '(oC)'\n",
    "    ws['F2'] = '(mm)'\n",
    "    ws['G2'] = '(mm)'\n",
    "    ws['H2'] = '(kPa)'\n",
    "    ws['I2'] = '(hours)'\n",
    "    ws.insert_rows(1)\n",
    "    ws['A1'] = '!Weather generated using C-CHANGE Foresite framework'\n",
    "    ws.insert_rows(1)\n",
    "    ws['A1'] = f'amp = {amp}'\n",
    "    ws.insert_rows(1)\n",
    "    ws['A1'] = f'tav = {tav}'\n",
    "    ws.insert_rows(1)\n",
    "    ws['A1'] = f'longitude = {long} (DECIMAL DEGREES)'\n",
    "    ws.insert_rows(1)\n",
    "    ws['A1'] = f'latitude = {lat} (DECIMAL DEGREES)'\n",
    "    ws.insert_rows(1)\n",
    "    ws['A1'] = 'stationname = Daymet weather'\n",
    "    ws.insert_rows(1)\n",
    "    ws['A1'] = '[weather.met.weather]'\n",
    "    wb.save(f'apsim_files/{county_name}/met_files/{county_name}.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create all met files for each county in a given geometry.\n",
    "\n",
    "Args:\n",
    "    dbconn {database connection} -- connection to postgresql database\n",
    "    counties {array/list} -- every county to be run on in the geometry\n",
    "    table {str} -- name of the table within the database to get geometries from\n",
    "    id_column {str} -- table column that has unique ids (in this case fips) for each county.\n",
    "    geo_col {str} -- table column that has geometry.\n",
    "    name_col {str} -- column that has the name for each county - can just use fips columns if no county names in table.\n",
    "\n",
    "Returns:\n",
    "    Met file for each county in counties.\n",
    "\"\"\"\n",
    "def create_all_met(dbconn, counties, table, id_col='fips', geo_col='wkb_geometry', name_col='county'):\n",
    "    for i in counties:\n",
    "        county = get_county(dbconn, table, i, geo_col)\n",
    "        county_name = county[name_col][0].replace(\" \", \"_\")\n",
    "        print(f'Geopandas table for {county_name} county created.')\n",
    "        centroid = get_centroid(county, id_col, geo_col)\n",
    "        print(f'Centroid located at {centroid}.')\n",
    "        weather = create_excel_met(centroid[0], centroid[1], 1980, 2019, county_name)\n",
    "        print(f\"Met file for {county_name}/{i} at location {centroid} created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_all_excel_met(dbconn, counties, table, id_col='fips', geo_col='wkb_geometry', name_col='county'):\n",
    "    for i in counties:\n",
    "        county = get_county(dbconn, table, i, geo_col)\n",
    "        county_name = county[name_col][0].replace(\" \", \"_\")\n",
    "        print(f'Geopandas table for {county_name} county created.')\n",
    "        centroid = get_centroid(county, id_col, geo_col)\n",
    "        print(f'Centroid located at {centroid}.')\n",
    "        if not os.path.exists(f'apsim_files/{county_name}/met_files'):\n",
    "            os.makedirs(f'apsim_files/{county_name}/met_files')\n",
    "        create_excel_met(centroid[0], centroid[1], 1980, 2019, county_name)\n",
    "        print(f\"Met file for {county_name}/{i} at location {centroid} created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Get all distinct counties and create met files for all county geometry lat/lon"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Geopandas table for Calhoun county created.\nCentroid located at [ 42.38220278 -94.64373465].\nMet file for Calhoun/IA025 at location [ 42.38220278 -94.64373465] created.\nGeopandas table for Buena_Vista county created.\nCentroid located at [ 42.72360279 -95.07483597].\nMet file for Buena_Vista/IA021 at location [ 42.72360279 -95.07483597] created.\nGeopandas table for Boone county created.\nCentroid located at [ 41.90142452 -94.14423565].\nMet file for Boone/IA015 at location [ 41.90142452 -94.14423565] created.\nGeopandas table for Hamilton county created.\nCentroid located at [ 42.40103778 -94.27051064].\nMet file for Hamilton/IA079 at location [ 42.40103778 -94.27051064] created.\nGeopandas table for Pocahontas county created.\nCentroid located at [ 42.70625119 -94.81755961].\nMet file for Pocahontas/IA151 at location [ 42.70625119 -94.81755961] created.\nGeopandas table for Clay county created.\nCentroid located at [ 42.9126454  -94.96637124].\nMet file for Clay/IA041 at location [ 42.9126454  -94.96637124] created.\nGeopandas table for Cherokee county created.\nCentroid located at [ 42.69440543 -95.27692498].\nMet file for Cherokee/IA035 at location [ 42.69440543 -95.27692498] created.\nGeopandas table for Palo_Alto county created.\nCentroid located at [ 42.91602769 -94.87930864].\nMet file for Palo_Alto/IA147 at location [ 42.91602769 -94.87930864] created.\nGeopandas table for Madison county created.\nCentroid located at [ 41.49169581 -94.02374479].\nMet file for Madison/IA121 at location [ 41.49169581 -94.02374479] created.\nGeopandas table for Greene county created.\nCentroid located at [ 42.03216389 -94.41357552].\nMet file for Greene/IA073 at location [ 42.03216389 -94.41357552] created.\nGeopandas table for Guthrie county created.\nCentroid located at [ 41.70807465 -94.48049267].\nMet file for Guthrie/IA077 at location [ 41.70807465 -94.48049267] created.\nGeopandas table for Warren county created.\nCentroid located at [ 41.52722958 -93.78185245].\nMet file for Warren/IA181 at location [ 41.52722958 -93.78185245] created.\nGeopandas table for Polk county created.\nCentroid located at [ 41.61376289 -93.78155529].\nMet file for Polk/IA153 at location [ 41.61376289 -93.78155529] created.\nGeopandas table for Webster county created.\nCentroid located at [ 42.31434054 -94.30152911].\nMet file for Webster/IA187 at location [ 42.31434054 -94.30152911] created.\nGeopandas table for Audubon county created.\nCentroid located at [ 41.79446464 -94.75177055].\nMet file for Audubon/IA009 at location [ 41.79446464 -94.75177055] created.\nGeopandas table for Dallas county created.\nCentroid located at [ 41.66179609 -94.08109363].\nMet file for Dallas/IA049 at location [ 41.66179609 -94.08109363] created.\nGeopandas table for Sac county created.\nCentroid located at [ 42.39313351 -94.98858463].\nMet file for Sac/IA161 at location [ 42.39313351 -94.98858463] created.\nGeopandas table for Crawford county created.\nCentroid located at [ 42.1116903  -94.96741953].\nMet file for Crawford/IA047 at location [ 42.1116903  -94.96741953] created.\nGeopandas table for Carroll county created.\nCentroid located at [ 42.05128975 -94.82033739].\nMet file for Carroll/IA027 at location [ 42.05128975 -94.82033739] created.\nGeopandas table for Adair county created.\nCentroid located at [ 41.5280692  -94.33637859].\nMet file for Adair/IA001 at location [ 41.5280692  -94.33637859] created.\n"
    }
   ],
   "source": [
    "fips = get_distinct(dbconn, raccoon_2018, 'fips')\n",
    "#create_all_met(dbconn, fips, raccoon_2018)\n",
    "create_all_excel_met(dbconn, fips, raccoon_2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Get clukey crop rotations"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Get the crop rotation for each clukey.\n",
    "\n",
    "Args:\n",
    "    df {obj} -- Dataframe that contains individual clukey information.\n",
    "    crop_column {str} -- Column name that contains the label for what crop is growing for a given year.\n",
    "\n",
    "Returns:\n",
    "    Str of the rotation. e.g., 'cs' = corn-soy\n",
    "\"\"\"\n",
    "def get_rotation(df, crop_column):\n",
    "    #save rotation for clukey to crops list\n",
    "    crops = []\n",
    "    for i in df.index:\n",
    "        val = df.loc[i, crop_column]\n",
    "        if val == 'Corn' or val == 'Soybean':\n",
    "            crops.append(val)\n",
    "        else:\n",
    "            crops.append('other')\n",
    "    #evaluate crops list and return a rotation\n",
    "    if all(x in crops for x in ['Corn', 'Soybean']):\n",
    "        rotation = 'cs'\n",
    "    elif all(x in crops for x in ['Corn']):\n",
    "        rotation = 'cc'\n",
    "    else:\n",
    "        rotation = 'other'\n",
    "    return rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rots = pd.read_sql('SELECT * FROM raccoon.raccoon_rots', dbconn)\n",
    "rots = pd.read_sql('SELECT * FROM raccoon.raccoon_rots;', dbconn)\n",
    "rots['rotation'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group df by clukey, sort by year, then loop through and get rotation, appending to original df.\n",
    "grouped = rots.groupby('clukey')\n",
    "clukeys = rots.drop_duplicates('clukey')\n",
    "for i in clukeys['clukey']:\n",
    "    field = grouped.get_group(i).sort_values(by=['years'], ascending=True)\n",
    "    rotation = get_rotation(field, 'crop')\n",
    "    rots.loc[rots['clukey'] == i, 'rotation'] = rotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Get the soil properties for each individual mukey"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#field_25 = pd.read_sql(f\"SELECT * FROM {raccoon_2018} WHERE clukey=2515723;\", dbconn)\n",
    "#greene = pd.read_sql(f\"SELECT * FROM {raccoon_2018} WHERE County='Greene';\", dbconn)\n",
    "#greene_soils = pd.read_sql(f\"SELECT DISTINCT mukey FROM {raccoon_2018} where County='Greene';\", dbconn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop through all rows - don't run"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def create_input_table(dbconn, table, fip, start_year=2016, end_year=2018, id_col='fips', geo_col='wkb_geometry', name_col='county', soil_col=\"mukey\", limit=False):\n",
    "def create_apsim_files(df, rotations_df, dbconn, field_key='clukey', soil_key='mukey', county_col='county', rotation_col='rotation', crop_col='crop', start_year=2016, end_year=2018):\n",
    "    if not os.path.exists('apsim_files'):\n",
    "        os.makedirs('apsim_files')\n",
    "    start_date = f'01/01/{start_year}'\n",
    "    end_date = f'31/12/{end_year}'\n",
    "    #save rotation for clukey to crops list\n",
    "    #loop through field keys e.g., clukeys\n",
    "    sim_count = 0\n",
    "    for i in df[field_key]:\n",
    "        field_id = i\n",
    "        #get field information\n",
    "        #TODO get 'clukey' and 'county' to work as function inputs instead of hardcoded\n",
    "        field = df.loc[df['clukey'] == i]\n",
    "        #get field rotation\n",
    "        rotation_row = rotations_df.loc[rotations_df[field_key] == i]\n",
    "        rotation = get_rotation(rotation_row, crop_col)\n",
    "        #get unique soil keys e.g., mukeys\n",
    "        soils = field.drop_duplicates(soil_key)\n",
    "        runs = soils['mukey']\n",
    "        #get weather file for desired county\n",
    "        county_name = field.iloc[0]['county'].replace(\" \", \"_\")\n",
    "        met_name = f\"{county_name}.met\"\n",
    "        met_path = f\"met_files/{met_name}\"\n",
    "        #create apsim file for each unique soil in field\n",
    "        for i in runs:\n",
    "            try:\n",
    "                soil_id = i\n",
    "                soil_query = '''select * from api.get_soil_properties( array[{}]::text[] )'''.format( i )\n",
    "                soil_df = pd.read_sql( soil_query, dbconn )\n",
    "                if soil_df.empty:\n",
    "                    continue\n",
    "                #soil_row = soils_df.loc[soils_df[f'{soil_key}'] == i]\n",
    "                #initialize .apsim xml\n",
    "                apsim_xml = Element( 'folder' )\n",
    "                apsim_xml.set( 'version', '36' )\n",
    "                apsim_xml.set( 'creator', 'C-CHANGE Foresite' )\n",
    "                apsim_xml.set( 'name', county_name )\n",
    "                sim = SubElement( apsim_xml, 'simulation' )\n",
    "                sim.set( 'name', f'{county_name} {field_id}' )\n",
    "                \n",
    "                #set met file\n",
    "                metfile = SubElement( sim, 'metfile' )\n",
    "                metfile.set( 'name', f'{county_name}' )\n",
    "                filename = SubElement( metfile, 'filename' )\n",
    "                filename.set( 'name', 'filename' )\n",
    "                filename.set( 'input', 'yes' )\n",
    "                filename.text = met_path\n",
    "\n",
    "                #set clock\n",
    "                clock = SubElement( sim, 'clock' )\n",
    "                clock_start = SubElement( clock, 'start_date' )\n",
    "                clock_start.set( 'type', 'date' )\n",
    "                clock_start.set( 'description', 'Enter the start date of the simulation' )\n",
    "                clock_start.text = start_date\n",
    "                clock_end = SubElement( clock, 'end_date' )\n",
    "                clock_end.set( 'type', 'date' )\n",
    "                clock_end.set( 'description', 'Enter the end date of the simulation' )\n",
    "                clock_end.text = end_date\n",
    "                sumfile = SubElement( sim, 'summaryfile' )\n",
    "                area = SubElement( sim, 'area' )\n",
    "                area.set( 'name', 'paddock' )\n",
    "\n",
    "                # add soil xml\n",
    "                soil = apsim.Soil( soil_df, SWIM = False, SaxtonRawls = False )\n",
    "                area.append( soil.soil_xml() )\n",
    "                ### surface om\n",
    "                surfom_xml = apsim.init_surfaceOM( 'maize', 'maize', 3500, 65, 0.0 )\n",
    "                area.append( surfom_xml )\n",
    "                ### fertilizer\n",
    "                fert_xml = SubElement( area, 'fertiliser' )\n",
    "\n",
    "                ### crops\n",
    "                crop_xml = SubElement( area, 'maize' )\n",
    "                crop_xml = SubElement( area, 'soybean' )\n",
    "                crop_xml = SubElement( area, 'wheat' )\n",
    "\n",
    "                ### output file\n",
    "                outvars = [\n",
    "                    'dd/mm/yyyy as Date', 'day', 'year',\n",
    "                    'yield', 'biomass', 'fertiliser',\n",
    "                    'surfaceom_c', 'subsurface_drain',\n",
    "                    'subsurface_drain_no3', 'leach_no3',\n",
    "                    'corn_buac', 'soy_buac' ]\n",
    "                output_xml = apsim.set_output_variables( f'{county_name}_{field_id}_{soil_id}.out', outvars )\n",
    "                area.append( output_xml )\n",
    "\n",
    "                graph_no3 = [\n",
    "                    'Cumulative subsurface_drain',\n",
    "                    'Cumulative subsurface_drain_no3',\n",
    "                    'Cumulative leach_no3'\n",
    "                ]\n",
    "                graph_yield = [\n",
    "                    'yield',\n",
    "                    'biomass',\n",
    "                    'corn_buac'\n",
    "                ]\n",
    "                graph_all = [\n",
    "                    'yield', 'biomass', 'fertiliser',\n",
    "                    'surfaceom_c', 'Cumulative subsurface_drain',\n",
    "                    'Cumulative subsurface_drain_no3',\n",
    "                    'Cumulative leach_no3', 'corn_buac',\n",
    "                    'soy_buac'\n",
    "                ]\n",
    "\n",
    "                output_xml.append( apsim.add_xy_graph( 'Date', graph_no3, 'no3' ) )\n",
    "                output_xml.append( apsim.add_xy_graph( 'Date', graph_yield, 'yield' ) )\n",
    "                output_xml.append( apsim.add_xy_graph( 'Date', graph_all, 'all outputs' ) )\n",
    "\n",
    "                op_man = apsim.OpManager()\n",
    "                op_man.add_empty_manager()\n",
    "                if rotation == 'cs':\n",
    "                    add_management_year(op_man, spin_up_corn, 2016)\n",
    "                    add_management_year(op_man, spin_up_soybean, 2017)\n",
    "                    add_management_year(op_man, spin_up_corn, 2018)\n",
    "                elif rotation == 'cc':\n",
    "                    add_management_year(op_man, spin_up_corn, 2018)\n",
    "                    add_management_year(op_man, spin_up_corn, 2016)\n",
    "                    add_management_year(op_man, spin_up_corn, 2017)\n",
    "                else:\n",
    "                    continue\n",
    "                area.append( op_man.man_xml )\n",
    "                outfile = f'apsim_files/{county_name}_{field_id}_{soil_id}.apsim'\n",
    "                ### management data\n",
    "                tree = ElementTree()\n",
    "                tree._setroot( apsim_xml )\n",
    "                tree.write( outfile )\n",
    "                sim_count += 1\n",
    "                if (sim_count % 5 == 0):\n",
    "                    print(f'Finished with {sim_count} files.')\n",
    "            except:\n",
    "                print(f'File creation failed for APSIM run {sim_count}')\n",
    "                sim_count +=1\n",
    "                continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just loop through unique soils for a given county"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "greene_soils = pd.read_sql(f\"SELECT DISTINCT mukey FROM {raccoon_2018} where County='Greene';\", dbconn)\n",
    "greene_soils_list = list(greene_soils['mukey'][0:5])\n",
    "#greene_test = greene_soils_list[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['703831', '403511', '406211', '403455', '406372']"
     },
     "metadata": {},
     "execution_count": 104
    }
   ],
   "source": [
    "greene_soils_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def county_mukey_runs(soils_list, dbconn, rotation, county_name, fips, start_year=2016, end_year=2018):\n",
    "    if not os.path.exists(f'apsim_files/{county_name}'):\n",
    "        os.makedirs(f'apsim_files/{county_name}')\n",
    "    start_date = f'01/01/{start_year}'\n",
    "    end_date = f'31/12/{end_year}'\n",
    "    #save rotation for clukey to crops list\n",
    "    #loop through field keys e.g., clukeys\n",
    "    sim_count = 0\n",
    "    met_name = f\"{county_name}.met\"\n",
    "    met_path = f\"met_files/{met_name}\"\n",
    "    for i in soils_list:\n",
    "        try:\n",
    "            soil_id = i\n",
    "            soil_query = '''select * from api.get_soil_properties( array[{}]::text[] )'''.format( i )\n",
    "            soil_df = pd.read_sql( soil_query, dbconn )\n",
    "            if soil_df.empty:\n",
    "                continue\n",
    "            #soil_row = soils_df.loc[soils_df[f'{soil_key}'] == i]\n",
    "            #initialize .apsim xml\n",
    "            apsim_xml = Element( 'folder' )\n",
    "            apsim_xml.set( 'version', '36' )\n",
    "            apsim_xml.set( 'creator', 'C-CHANGE Foresite' )\n",
    "            apsim_xml.set( 'name', county_name )\n",
    "            sim = SubElement( apsim_xml, 'simulation' )\n",
    "            sim.set( 'name', f'County_{county_name}_{fips}_mukey_{soil_id}_rot_{rotation}' )\n",
    "            \n",
    "            #set met file\n",
    "            metfile = SubElement( sim, 'metfile' )\n",
    "            metfile.set( 'name', f'{county_name}' )\n",
    "            filename = SubElement( metfile, 'filename' )\n",
    "            filename.set( 'name', 'filename' )\n",
    "            filename.set( 'input', 'yes' )\n",
    "            filename.text = met_path\n",
    "\n",
    "            #set clock\n",
    "            clock = SubElement( sim, 'clock' )\n",
    "            clock_start = SubElement( clock, 'start_date' )\n",
    "            clock_start.set( 'type', 'date' )\n",
    "            clock_start.set( 'description', 'Enter the start date of the simulation' )\n",
    "            clock_start.text = start_date\n",
    "            clock_end = SubElement( clock, 'end_date' )\n",
    "            clock_end.set( 'type', 'date' )\n",
    "            clock_end.set( 'description', 'Enter the end date of the simulation' )\n",
    "            clock_end.text = end_date\n",
    "            sumfile = SubElement( sim, 'summaryfile' )\n",
    "            area = SubElement( sim, 'area' )\n",
    "            area.set( 'name', 'paddock' )\n",
    "\n",
    "            # add soil xml\n",
    "            soil = apsim.Soil( soil_df, SWIM = False, SaxtonRawls = False )\n",
    "            area.append( soil.soil_xml() )\n",
    "            ### surface om\n",
    "            surfom_xml = apsim.init_surfaceOM( 'maize', 'maize', 3500, 65, 0.0 )\n",
    "            area.append( surfom_xml )\n",
    "            ### fertilizer\n",
    "            fert_xml = SubElement( area, 'fertiliser' )\n",
    "\n",
    "            ### crops\n",
    "            crop_xml = SubElement( area, 'maize' )\n",
    "            crop_xml = SubElement( area, 'soybean' )\n",
    "            #crop_xml = SubElement( area, 'wheat' )\n",
    "\n",
    "            ### output file\n",
    "            outvars = [\n",
    "                'dd/mm/yyyy as Date', 'day', 'year',\n",
    "                'yield', 'biomass', 'fertiliser',\n",
    "                'surfaceom_c', 'subsurface_drain',\n",
    "                'subsurface_drain_no3', 'leach_no3',\n",
    "                'corn_buac', 'soy_buac' ]\n",
    "            output_xml = apsim.set_output_variables( f'{county_name}_{fips}_mukey_{soil_id}.out', outvars )\n",
    "            area.append( output_xml )\n",
    "            graph_no3 = [\n",
    "                'Cumulative subsurface_drain',\n",
    "                'Cumulative subsurface_drain_no3',\n",
    "                'Cumulative leach_no3'\n",
    "            ]\n",
    "            graph_yield = [\n",
    "                'yield',\n",
    "                'biomass',\n",
    "                'corn_buac'\n",
    "            ]\n",
    "            graph_all = [\n",
    "                'yield', 'biomass', 'fertiliser',\n",
    "                'surfaceom_c', 'Cumulative subsurface_drain',\n",
    "                'Cumulative subsurface_drain_no3',\n",
    "                'Cumulative leach_no3', 'corn_buac',\n",
    "                'soy_buac'\n",
    "            ]\n",
    "\n",
    "            output_xml.append( apsim.add_xy_graph( 'Date', graph_no3, 'no3' ) )\n",
    "            output_xml.append( apsim.add_xy_graph( 'Date', graph_yield, 'yield' ) )\n",
    "            output_xml.append( apsim.add_xy_graph( 'Date', graph_all, 'all outputs' ) )\n",
    "\n",
    "            op_man = apsim.OpManager()\n",
    "            op_man.add_empty_manager()\n",
    "            if rotation == 'cfs':\n",
    "                add_management_year(op_man, spin_up_corn, 2016)\n",
    "                add_management_year(op_man, spin_up_soybean, 2017)\n",
    "                add_management_year(op_man, spin_up_corn, 2018)\n",
    "            elif rotation == 'sfc':\n",
    "                add_management_year(op_man, spin_up_soybean, 2016)\n",
    "                add_management_year(op_man, spin_up_corn, 2017)\n",
    "                add_management_year(op_man, spin_up_soybean, 2018)\n",
    "            else:\n",
    "                add_management_year(op_man, spin_up_corn, 2016)\n",
    "                add_management_year(op_man, spin_up_corn, 2017)\n",
    "                add_management_year(op_man, spin_up_corn, 2018)\n",
    "            \n",
    "            area.append( op_man.man_xml )\n",
    "            outfile = f'apsim_files/{county_name}/{county_name}_{soil_id}_{rotation}.apsim'\n",
    "            ### management data\n",
    "            tree = ElementTree()\n",
    "            tree._setroot( apsim_xml )\n",
    "            tree.write( outfile )\n",
    "            sim_count += 1\n",
    "            if (sim_count % 5 == 0):\n",
    "                print(f'Finished with {sim_count} files.')\n",
    "        except:\n",
    "            print(f'File creation failed for APSIM run {sim_count} mukey {soil_id}')\n",
    "            sim_count +=1\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_mukey_runs(greene_soils_list, dbconn, 'cfs', 'Greene', 'IA073')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "greene_403 = pd.read_csv( 'C:\\\\Users\\\\mnowatz\\\\Documents\\\\Dev\\\\aepe\\\\analyses\\\\apsim_files\\\\Greene\\\\County_Greene_IA073_mukey_403455_rot_cfs.out', header = 3, delim_whitespace = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "              Date    day    year paddock.soybean.yield paddock.wheat.yield  \\\n0     (dd/mm/yyyy)  (day)  (year)               (kg/ha)             (kg/ha)   \n1       01/01/2016      1    2016               0.00000             0.00000   \n2       02/01/2016      2    2016               0.00000             0.00000   \n3       03/01/2016      3    2016               0.00000             0.00000   \n4       04/01/2016      4    2016               0.00000             0.00000   \n...            ...    ...     ...                   ...                 ...   \n1092    27/12/2018    361    2018            2563.74414             0.00000   \n1093    28/12/2018    362    2018            2563.74414             0.00000   \n1094    29/12/2018    363    2018            2563.74414             0.00000   \n1095    30/12/2018    364    2018            2563.74414             0.00000   \n1096    31/12/2018    365    2018            2563.74414             0.00000   \n\n     paddock.maize.yield paddock.soybean.biomass paddock.wheat.biomass  \\\n0                (kg/ha)                 (kg/ha)               (kg/ha)   \n1                0.00000                 0.00000               0.00000   \n2                0.00000                 0.00000               0.00000   \n3                0.00000                 0.00000               0.00000   \n4                0.00000                 0.00000               0.00000   \n...                  ...                     ...                   ...   \n1092             0.00000              5954.30420               0.00000   \n1093             0.00000              5954.30420               0.00000   \n1094             0.00000              5954.30420               0.00000   \n1095             0.00000              5954.30420               0.00000   \n1096             0.00000              5954.30420               0.00000   \n\n     paddock.maize.biomass fertiliser surfaceom_c subsurface_drain  \\\n0                  (kg/ha)    (kg/ha)     (kg/ha)               ()   \n1                  0.00000    0.00000  1400.00000                ?   \n2                  0.00000    0.00000  1400.00000                ?   \n3                  0.00000    0.00000  1400.00000                ?   \n4                  0.00000    0.00000  1400.00000                ?   \n...                    ...        ...         ...              ...   \n1092               0.00000    0.00000  2555.41943                ?   \n1093               0.00000    0.00000  2555.37598                ?   \n1094               0.00000    0.00000  2555.37598                ?   \n1095               0.00000    0.00000  2555.37598                ?   \n1096               0.00000    0.00000  2555.37598                ?   \n\n     subsurface_drain_no3 leach_no3 corn_buac  soy_buac  \n0                      ()   (kg/ha)        ()        ()  \n1                       ?   0.00000   0.00000   0.00000  \n2                       ?   0.00000   0.00000   0.00000  \n3                       ?   0.00000   0.00000   0.00000  \n4                       ?   0.00000   0.00000   0.00000  \n...                   ...       ...       ...       ...  \n1092                    ?   0.25412   0.00000  43.90780  \n1093                    ?   0.25424   0.00000  43.90780  \n1094                    ?   0.24779   0.00000  43.90780  \n1095                    ?   0.23665   0.00000  43.90780  \n1096                    ?   0.22221   0.00000  43.90780  \n\n[1097 rows x 16 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>day</th>\n      <th>year</th>\n      <th>paddock.soybean.yield</th>\n      <th>paddock.wheat.yield</th>\n      <th>paddock.maize.yield</th>\n      <th>paddock.soybean.biomass</th>\n      <th>paddock.wheat.biomass</th>\n      <th>paddock.maize.biomass</th>\n      <th>fertiliser</th>\n      <th>surfaceom_c</th>\n      <th>subsurface_drain</th>\n      <th>subsurface_drain_no3</th>\n      <th>leach_no3</th>\n      <th>corn_buac</th>\n      <th>soy_buac</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>(dd/mm/yyyy)</td>\n      <td>(day)</td>\n      <td>(year)</td>\n      <td>(kg/ha)</td>\n      <td>(kg/ha)</td>\n      <td>(kg/ha)</td>\n      <td>(kg/ha)</td>\n      <td>(kg/ha)</td>\n      <td>(kg/ha)</td>\n      <td>(kg/ha)</td>\n      <td>(kg/ha)</td>\n      <td>()</td>\n      <td>()</td>\n      <td>(kg/ha)</td>\n      <td>()</td>\n      <td>()</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>01/01/2016</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1400.00000</td>\n      <td>?</td>\n      <td>?</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>02/01/2016</td>\n      <td>2</td>\n      <td>2016</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1400.00000</td>\n      <td>?</td>\n      <td>?</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>03/01/2016</td>\n      <td>3</td>\n      <td>2016</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1400.00000</td>\n      <td>?</td>\n      <td>?</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>04/01/2016</td>\n      <td>4</td>\n      <td>2016</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1400.00000</td>\n      <td>?</td>\n      <td>?</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1092</th>\n      <td>27/12/2018</td>\n      <td>361</td>\n      <td>2018</td>\n      <td>2563.74414</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>5954.30420</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>2555.41943</td>\n      <td>?</td>\n      <td>?</td>\n      <td>0.25412</td>\n      <td>0.00000</td>\n      <td>43.90780</td>\n    </tr>\n    <tr>\n      <th>1093</th>\n      <td>28/12/2018</td>\n      <td>362</td>\n      <td>2018</td>\n      <td>2563.74414</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>5954.30420</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>2555.37598</td>\n      <td>?</td>\n      <td>?</td>\n      <td>0.25424</td>\n      <td>0.00000</td>\n      <td>43.90780</td>\n    </tr>\n    <tr>\n      <th>1094</th>\n      <td>29/12/2018</td>\n      <td>363</td>\n      <td>2018</td>\n      <td>2563.74414</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>5954.30420</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>2555.37598</td>\n      <td>?</td>\n      <td>?</td>\n      <td>0.24779</td>\n      <td>0.00000</td>\n      <td>43.90780</td>\n    </tr>\n    <tr>\n      <th>1095</th>\n      <td>30/12/2018</td>\n      <td>364</td>\n      <td>2018</td>\n      <td>2563.74414</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>5954.30420</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>2555.37598</td>\n      <td>?</td>\n      <td>?</td>\n      <td>0.23665</td>\n      <td>0.00000</td>\n      <td>43.90780</td>\n    </tr>\n    <tr>\n      <th>1096</th>\n      <td>31/12/2018</td>\n      <td>365</td>\n      <td>2018</td>\n      <td>2563.74414</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>5954.30420</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>2555.37598</td>\n      <td>?</td>\n      <td>?</td>\n      <td>0.22221</td>\n      <td>0.00000</td>\n      <td>43.90780</td>\n    </tr>\n  </tbody>\n</table>\n<p>1097 rows × 16 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 157
    }
   ],
   "source": [
    "greene_403"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "greene_403_header = str(pd.read_csv('C:\\\\Users\\\\mnowatz\\\\Documents\\\\Dev\\\\aepe\\\\analyses\\\\apsim_files\\\\Greene\\\\County_Greene_IA073_mukey_403455_rot_cfs.out', header=2, nrows=0).columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\"['Title = County_Greene_IA073_mukey_403455_rot_cfs']\""
     },
     "metadata": {},
     "execution_count": 159
    }
   ],
   "source": [
    "greene_403_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "mukey_pattern = \"mukey_(.*?)_rot\"\n",
    "fips_pattern = \"Greene_(.*?)_mukey\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "mukey = int(re.search(mukey_pattern, greene_403_header).group(1))\n",
    "fips = re.search(fips_pattern, greene_403_header).group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "403455"
     },
     "metadata": {},
     "execution_count": 162
    }
   ],
   "source": [
    "mukey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'IA073'"
     },
     "metadata": {},
     "execution_count": 163
    }
   ],
   "source": [
    "fips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "greene_403.insert(0, 'fips', fips)\n",
    "greene_403.insert(1, 'mukey', mukey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "greene_403 = greene_403.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "greene_403 = greene_403.drop([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       fips   mukey        Date  day  year paddock.soybean.yield  \\\n1     IA073  403455  01/01/2016    1  2016               0.00000   \n2     IA073  403455  02/01/2016    2  2016               0.00000   \n3     IA073  403455  03/01/2016    3  2016               0.00000   \n4     IA073  403455  04/01/2016    4  2016               0.00000   \n5     IA073  403455  05/01/2016    5  2016               0.00000   \n...     ...     ...         ...  ...   ...                   ...   \n1092  IA073  403455  27/12/2018  361  2018            2563.74414   \n1093  IA073  403455  28/12/2018  362  2018            2563.74414   \n1094  IA073  403455  29/12/2018  363  2018            2563.74414   \n1095  IA073  403455  30/12/2018  364  2018            2563.74414   \n1096  IA073  403455  31/12/2018  365  2018            2563.74414   \n\n     paddock.wheat.yield paddock.maize.yield paddock.soybean.biomass  \\\n1                0.00000             0.00000                 0.00000   \n2                0.00000             0.00000                 0.00000   \n3                0.00000             0.00000                 0.00000   \n4                0.00000             0.00000                 0.00000   \n5                0.00000             0.00000                 0.00000   \n...                  ...                 ...                     ...   \n1092             0.00000             0.00000              5954.30420   \n1093             0.00000             0.00000              5954.30420   \n1094             0.00000             0.00000              5954.30420   \n1095             0.00000             0.00000              5954.30420   \n1096             0.00000             0.00000              5954.30420   \n\n     paddock.wheat.biomass paddock.maize.biomass fertiliser surfaceom_c  \\\n1                  0.00000               0.00000    0.00000  1400.00000   \n2                  0.00000               0.00000    0.00000  1400.00000   \n3                  0.00000               0.00000    0.00000  1400.00000   \n4                  0.00000               0.00000    0.00000  1400.00000   \n5                  0.00000               0.00000    0.00000  1400.00000   \n...                    ...                   ...        ...         ...   \n1092               0.00000               0.00000    0.00000  2555.41943   \n1093               0.00000               0.00000    0.00000  2555.37598   \n1094               0.00000               0.00000    0.00000  2555.37598   \n1095               0.00000               0.00000    0.00000  2555.37598   \n1096               0.00000               0.00000    0.00000  2555.37598   \n\n     subsurface_drain subsurface_drain_no3 leach_no3 corn_buac  soy_buac  \n1                   ?                    ?   0.00000   0.00000   0.00000  \n2                   ?                    ?   0.00000   0.00000   0.00000  \n3                   ?                    ?   0.00000   0.00000   0.00000  \n4                   ?                    ?   0.00000   0.00000   0.00000  \n5                   ?                    ?   0.00000   0.00000   0.00000  \n...               ...                  ...       ...       ...       ...  \n1092                ?                    ?   0.25412   0.00000  43.90780  \n1093                ?                    ?   0.25424   0.00000  43.90780  \n1094                ?                    ?   0.24779   0.00000  43.90780  \n1095                ?                    ?   0.23665   0.00000  43.90780  \n1096                ?                    ?   0.22221   0.00000  43.90780  \n\n[1096 rows x 18 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fips</th>\n      <th>mukey</th>\n      <th>Date</th>\n      <th>day</th>\n      <th>year</th>\n      <th>paddock.soybean.yield</th>\n      <th>paddock.wheat.yield</th>\n      <th>paddock.maize.yield</th>\n      <th>paddock.soybean.biomass</th>\n      <th>paddock.wheat.biomass</th>\n      <th>paddock.maize.biomass</th>\n      <th>fertiliser</th>\n      <th>surfaceom_c</th>\n      <th>subsurface_drain</th>\n      <th>subsurface_drain_no3</th>\n      <th>leach_no3</th>\n      <th>corn_buac</th>\n      <th>soy_buac</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>IA073</td>\n      <td>403455</td>\n      <td>01/01/2016</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1400.00000</td>\n      <td>?</td>\n      <td>?</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>IA073</td>\n      <td>403455</td>\n      <td>02/01/2016</td>\n      <td>2</td>\n      <td>2016</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1400.00000</td>\n      <td>?</td>\n      <td>?</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>IA073</td>\n      <td>403455</td>\n      <td>03/01/2016</td>\n      <td>3</td>\n      <td>2016</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1400.00000</td>\n      <td>?</td>\n      <td>?</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>IA073</td>\n      <td>403455</td>\n      <td>04/01/2016</td>\n      <td>4</td>\n      <td>2016</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1400.00000</td>\n      <td>?</td>\n      <td>?</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>IA073</td>\n      <td>403455</td>\n      <td>05/01/2016</td>\n      <td>5</td>\n      <td>2016</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>1400.00000</td>\n      <td>?</td>\n      <td>?</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1092</th>\n      <td>IA073</td>\n      <td>403455</td>\n      <td>27/12/2018</td>\n      <td>361</td>\n      <td>2018</td>\n      <td>2563.74414</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>5954.30420</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>2555.41943</td>\n      <td>?</td>\n      <td>?</td>\n      <td>0.25412</td>\n      <td>0.00000</td>\n      <td>43.90780</td>\n    </tr>\n    <tr>\n      <th>1093</th>\n      <td>IA073</td>\n      <td>403455</td>\n      <td>28/12/2018</td>\n      <td>362</td>\n      <td>2018</td>\n      <td>2563.74414</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>5954.30420</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>2555.37598</td>\n      <td>?</td>\n      <td>?</td>\n      <td>0.25424</td>\n      <td>0.00000</td>\n      <td>43.90780</td>\n    </tr>\n    <tr>\n      <th>1094</th>\n      <td>IA073</td>\n      <td>403455</td>\n      <td>29/12/2018</td>\n      <td>363</td>\n      <td>2018</td>\n      <td>2563.74414</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>5954.30420</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>2555.37598</td>\n      <td>?</td>\n      <td>?</td>\n      <td>0.24779</td>\n      <td>0.00000</td>\n      <td>43.90780</td>\n    </tr>\n    <tr>\n      <th>1095</th>\n      <td>IA073</td>\n      <td>403455</td>\n      <td>30/12/2018</td>\n      <td>364</td>\n      <td>2018</td>\n      <td>2563.74414</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>5954.30420</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>2555.37598</td>\n      <td>?</td>\n      <td>?</td>\n      <td>0.23665</td>\n      <td>0.00000</td>\n      <td>43.90780</td>\n    </tr>\n    <tr>\n      <th>1096</th>\n      <td>IA073</td>\n      <td>403455</td>\n      <td>31/12/2018</td>\n      <td>365</td>\n      <td>2018</td>\n      <td>2563.74414</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>5954.30420</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>2555.37598</td>\n      <td>?</td>\n      <td>?</td>\n      <td>0.22221</td>\n      <td>0.00000</td>\n      <td>43.90780</td>\n    </tr>\n  </tbody>\n</table>\n<p>1096 rows × 18 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 167
    }
   ],
   "source": [
    "greene_403"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "'Only a column name can be used for the key in a dtype mappings argument.'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-154-51b07dd3c6a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m greene_403 = greene_403.astype( {\n\u001b[0m\u001b[0;32m      2\u001b[0m             \u001b[1;34m'fips'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;34m'string'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m             \u001b[1;34m'mukey'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;34m'int64'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m             \u001b[1;34m'date'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;34m'datetime64'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[1;34m'day'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'int64'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\gis\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   5673\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mcol_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5674\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mcol_name\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5675\u001b[1;33m                     raise KeyError(\n\u001b[0m\u001b[0;32m   5676\u001b[0m                         \u001b[1;34m\"Only a column name can be used for the \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5677\u001b[0m                         \u001b[1;34m\"key in a dtype mappings argument.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Only a column name can be used for the key in a dtype mappings argument.'"
     ]
    }
   ],
   "source": [
    "greene_403 = greene_403.astype( {\n",
    "            'fips' : 'string',\n",
    "            'mukey' : 'int64',\n",
    "            'date' : 'datetime64',\n",
    "            'day': 'int64',\n",
    "            'year': 'int64',\n",
    "            'yield': 'float64',\n",
    "            'biomass': 'float64',\n",
    "            'fertiliser': 'float64',\n",
    "            #'n2o_atm': 'float64',\n",
    "            'surfaceom_c': 'float64',\n",
    "            'subsurface_drain': 'float64',\n",
    "            'subsurface_drain_no3': 'float64',\n",
    "            'leach_no3': 'float64',\n",
    "            'corn_buac' : 'float64',\n",
    "            'soy_buac' : 'float64'\n",
    "        } )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df = pd.read_csv( file, header = [3,4], delim_whitespace = True )\n",
    "df_header = str(pd.read_csv(file, header=2, nrows=0).columns.values)\n",
    "mukey_pattern = \"mukey_(.*?)_rot\"\n",
    "mukey = int(re.search(mukey_pattern, df_header).group(1))\n",
    "fips_pattern = \"_(.*?)_mukey\"\n",
    "fips_str = re.search(fips_pattern, df_header).group(1)\n",
    "daily_df.insert(1, 'fips', fips_str)\n",
    "daily_df.insert(2, 'mukey', mukey)\n",
    "daily_df = daily_df.reset_index( drop = True )"
   ]
  }
 ]
}